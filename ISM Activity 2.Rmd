---
title: "Intermediate Statistical Methods"
author: "Ahmed Bediwy (01466320); Mubarak Mojoyinola (01451893); Geraldo Padilla (01445225)"
date: "10/06/2021"
output:
  word_document: default
  html_document: default
  pdf_document: default
params:
  x: 20
subtitle: Activity 2
bibliography: Biblio.bib
csl: apa.csl.txt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Introduction**

This activity explores the relationship between variables in a data set referred to Uber and Lyft rideshares in Boston, MA. The data set is a random sample of 2.500 observations from 693.071 cases in the original database, available at  <https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma>

```{r, echo=FALSE, warning=FALSE, message=FALSE}
urlfile<-'https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/rideshare_small.csv'
ride<-read.csv(url(urlfile))
library("easypackages")
paq <- c('e1071','lubridate', 'mosaic', 'ggformula', 'paramtest', 'pwr', 'ggplot2', 'nlme', 'dplyr', 'knitr', 'dplyr', 'dbplyr', 'readxl', 'GGally', 'Hmisc', 'corrplot', 'PerformanceAnalytics', 'statthink', 'tidyverse')
libraries(paq)
theme_set(theme_statthinking())
```

**Guiding question**

Does the distance of the ride explain variation in the price of the ride?

1. This assignment uses the same data from the first activity. Take a few minutes to reacquaint yourself with this analysis, including the linear regression estimates obtained.

```{r}
ride_lm <- lm(price ~ distance, data = ride)
coef(ride_lm)
summary(ride_lm)$r.square
summary(ride_lm)$sigma
```

The intercept is $10.44 and the slope is $2.89. The estimated price values will be:

$$
\hat{price} = 10.439 + 2.889 distance
$$
Moreover, the variability of prices accounted for distance is 12.44%, and the dispersion of the observed values of price respect with the predicted values by the model is, on average, $8.77.

Graphically, the relationship between price and distance look like:

```{r}
gf_point(price ~ distance, data = ride, size = 4, alpha = .2) %>%
  gf_labs(x = "Distance of the ride",
          y = "Price of the ride") %>%
  gf_smooth() %>%
  gf_smooth(method = 'lm', color = 'lightblue', linetype = 2)
```

2. Was the intercept from the linear regression fitted in activity 1 using the raw data as is interpretable in the context of the data? Rephrasing slightly, could the intercept term be made more interpretable? If so, how?

Table 1

```{r, message=FALSE}
st1 <- df_stats(~ price, data = ride, mean, min, max, median, sd, quantile(probs = c(0.25, 0.75)))
st2 <- df_stats(~ distance, data = ride, min, max, mean, median, sd, quantile(probs = c(0.25, 0.75)))
st <- rbind(st1, st2)
head(st)
```

Some descriptive statistics for the two variables included into the simple linear regression are shown in the Table 1. The minimum value of distance is close to 0 (0.03), which does the y-intercept quite interpretable. However, we can perform a minimum-centering transformation of distance to achieve a more interpretable y-intercept.
  
3. Fit a modified linear regression that performs a centering. That is, center the distance in some fashion. Options could include, minimum, mean, median, maximum, etc centering. What changed for the estimates obtained from the model?

```{r}
ride <- ride %>%
  mutate(distance_min = distance - min(distance))
ride_lm_min <- lm(price ~ distance_min, data = ride)
coef(ride_lm_min)
```

According to the context of the problem, on average, the price of the rides is $10.53 when distance travel is 0.03 miles (minimum value).

The new relationship look like:

```{r}
gf_point(price ~ distance_min, data = ride, size = 4, alpha = .15) %>%
  gf_labs(x = "Distance of the ride",
          y = "Price of the ride") %>%
  gf_smooth() %>%
  gf_smooth(method = 'lm', color = 'lightblue', linetype = 2)
```

As the structural relationship between the two variables has not changed, the slope still being the same as the previous model.

4. Which model, the centered or the uncentered, do you feel has a stronger justification for its usage? Be as specific as possible in your rationale. Use whichever model you feel is the best from #3, then extract from software or compute the standard errors for the estimated regression coefficients. Interpret these standard errors in the context of the problem.

The minimum-centered transformation of the distance is the most intuitive option. It slightly affects the y-intercept and offers more advantages than disadvantages.

```{r}
summary <- summary(ride_lm_min)
summary$coefficients[,2]
```

The standard errors (s.e.) of the estimated parameters are .37 for b0 and .15 for b1. This represents the uncertainty in the estimation of the population parameters B0 and B1. If another sample were extracted from the population, the expected variability between the current estimated parameters and the new ones will be, on average, $.37 for price at the minimum distance value and $.15 per change in miles (distance).

5. Compute confidence intervals for the two regression coefficients. Justify your choice for level of confidence and interpret the confidence interval.

```{r}
coef(ride_lm_min)
summary(ride_lm_min)$coefficients[,2]
CI_b0 <- 10.525840 + c(-1, 1) * 1.96 * 0.3784202
CI_b1 <- 2.889949 + c(-1, 1) * 1.96 * 0.1533785
CI_b0
CI_b1
```

The justification for using the 95% confidence level is to ensure the price payed by clients is within the estimated intervals 95% of the times.

The interpretation of both CI are as follow:

- At the minimum value of distance in miles, the price of the rides will be, on average, somewhere between $9.78 and $11.27 (b0).
- With 95% of confidence, a 1-mile increase in distance is associated with a price increase from $2.59 to $3.19 (b1).

6. Finally, perform hypothesis testing for the two regression coefficients. In this, set up the null/alternative hypotheses and then interpret the statistical results to provide a statistical conclusion. More specifically, what does the hypothesis test suggest about the null and alternative hypotheses?

The null hypothesis for the parameters are as follow:

$$
H_{0}: \beta_{0} = 0.\ The\  population\  yintercept\  equals\  0.
$$
or

$$ 
H_{0}: \beta_{1} = 0.\ The\  population\  slope\  equals\  0.
$$
In both cases, the alternative hypothesis is that the parameters are different from zero, in other words, there is a relationship between distance and price of rides.

```{r}
t_b0 <- 10.525840/ 0.3784202
t_b1 <- 2.889949/ 0.1533785
t_b0
t_b1
```

Considering the t-statistic results, in both cases the null hypothesis can be rejected. In particular, the t-statistic of B0 (27.82) falls far away of the interval constructed with 95% of confidence; on the other hand, the t-statistic of B1 (18.84) also falls out of the interval constructed at 95% of confidence.

In addition, p-values support this interpretation (<.001). In other words, the probability that B0 and B1 parameters equal zero in the population is below 0.001. Finally, based on the CI, t-statistics and p-values, it can be concluded that there is some relationship between price and distance of rides.

```{r}
summary(ride_lm_min)
```

The first part talked about the statistical conclusions, now compare/contrast this with practical conclusions. More specifically, would these results be useful in practice? Be as specific as possible in your response.

Practically, there is non zero value for B0 because people pay after a minimum distance traveled. For the B1, the price increase for additional distance traveled.