---
title: "<center> <h1>Activity 1</h1> </center>"
author: ".."
output:
  word_document: default
  pdf_document: default
  html_document: default
---

# Introduction

```{r, echo=FALSE, warning=FALSE, message=FALSE}
urlfile<-'https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/rideshare_small.csv'
ride<-read.csv(url(urlfile))
library("easypackages")
paq <- c('psqf6246stat6516','e1071','lubridate', 'mosaic', 'ggformula', 'paramtest', 'pwr', 'ggplot2', 'nlme', 'dplyr', 'dbplyer', 'knitr', 'dplyr', 'dbplyr', 'readxl', 'GGally', 'Hmisc', 'corrplot', 'PerformanceAnalytics', 'statthink')
libraries(paq)
theme_set(theme_statthinking())
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, results='hide'}
list(ride)
head(ride)
str(ride)
```

In this assignment, we will explore some relationship between variables in a data set referred to Uber and Lyft rideshares in Boston, MA. The data set is a random sample of n= 2.500 observations from 693.071 observations in the original database, available at <https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma>

## Guiding question

Specifically, we have the following guiding question: does the distance of the ride explain variation in the price of the ride?

1. In this vein, the first thing to do is exploring the distribution of the `price` (dependent variable) of the rides (shape, center, variation, and/or extreme values).

Table 1 shows descriptive statistics in detail:

```{r, message=FALSE}
df_stats(~ price, data = ride, mean, min, max, median, sd, skewness, quantile(probs = c(0.25, 0.75)))
```

The mean is $16.84, with a standard deviation of $9.37.The range of values is $59.5, and the IQR is $13.00.

When exploring the Figure 1, `price` shows a positive skew. Moreover, the 50% of the values go from $9.50 up to $22.5.

Figure 1

```{r, echo=FALSE}
gf_histogram(~price, data = ride, color = 'black', fill = 'yellow', bins = 40) %>% 
  gf_boxploth(330 ~ price, data = ride, fill = "skyblue", width = 12) %>%
  gf_labs(x = "Total price of the ride (in $)", y = 'Frequency')
```

The density plot shows two peaks, which could be signal of a bimodal distribution. 

```{r, message=FALSE}
gf_density(~ price, data = ride)
```

2. Second, the bivariate distribution of the price of ride and distance of rides can be shown as follow.

Figure 2

```{r}
gf_point(price ~ distance, data = ride, size = 4, alpha = .5) %>% 
  gf_smooth(method = 'lm', linetype = 2, color = 'lightblue') %>%
  gf_labs(x = 'Distance of the ride',
          y = "Total price of the ride (in $)")
```

```{r, echo=FALSE, results='hide'}
cor(price ~ distance, data = ride)
```

The relationship between price and distance, based on the Pearson's correlation coefficient, is 0.353. This shows a positive but weak and slightly linear relationship.

3. Third, based on the previous analysis, the relationship between the two variables seems to be slightly linear, mainly because the correlation value is small.

4. To answer the guiding question, a linear regression is performed under the assumption that  price (response) is a function of distance (predictor).

```{r}
ride_lm <- lm(price ~ distance, data = ride)
coef(ride_lm)
```

The intercept is 10.44 and the slope is 2.89. But, what does this mean?

$$
\hat{price} = 10.439 + 2.889 distance
$$
For every single unit increase in distance (portions of miles), price increases, on average, by $2.89 (slope).
In absence of distance, the price of rides would be, on average, $10.44.

5. Other way to analyze the relationship between price and distance is using the r-square and sigma, measures of variability.

```{r}
summary(ride_lm)$r.square
summary(ride_lm)$sigma
```

First, the r-squared equals 12.4%, that is, the distance just explains, approximately, the 12% of the price variability. On the other hand, sigma shows that the observed prices varies from the predicted prices by  $8.77.

6. Summary of the model

In a nutshell, the current model does not fit the data correctly. To predict the prices of rides, distance appears not to be enough. This is especially true if we consider the R^2^ = 12.4% and the variability around the regression line expressed by sigma.