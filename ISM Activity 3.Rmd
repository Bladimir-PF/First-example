---
title: "ISM Activity 3"
author: "Geraldo B. Padilla F."
date: "10/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
ride <- readr::read_csv("https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/rideshare_small.csv")
library("easypackages")
paq <- c('e1071','lubridate', 'mosaic', 'ggformula', 'paramtest', 'pwr', 'ggplot2', 'nlme', 'knitr', 'dplyr', 'dbplyr', 'readxl', 'GGally', 'Hmisc', 'corrplot', 'PerformanceAnalytics', 'statthink', 'tidyverse')
libraries(paq)
theme_set(theme_statthinking())
```

**Introduction**

This activity explores the relationship between variables in a data set referred to Uber and Lyft rideshares in Boston, MA. The data set is a random sample of 2.500 observations from 693.071 cases in the original database, available at  <https://www.kaggle.com/brllrb/uber-and-lyft-dataset-boston-ma>

**Guiding Question**

Does the distance of the ride explain variation in the price of the ride?

Questions

1. This assignment uses the same data from the first and second activities. Take a few minutes to reacquaint yourself with these analyses, including the linear regression estimates obtained.

Based on the guiding question and previous analysis, the linear regressions results are as follow:

```{r}
ride_lm <- lm(price ~ distance, data = ride)
coef(ride_lm)
summary(ride_lm)$r.square
summary(ride_lm)$sigma
```

The intercept is 10.44 and the slope is 2.89. The estimated price values will be:

$$
\hat{price} = 10.439 + 2.889 \ distance
$$
Moreover, the variability of prices accounted for distance is $R^2$ = 12.44%, and the dispersion of the observed values of price respect with the predicted values by the model is, on average, $8.77.

Graphically, the relationship between price and distance look like:

```{r}
gf_point(price ~ distance, data = ride, size = 4, alpha = .2) %>%
  gf_labs(x = "Distance of the ride",
          y = "Price of the ride") %>%
  gf_smooth() %>%
  gf_smooth(method = 'lm', color = 'lightblue', linetype = 2)
```

2. Extract the residuals from one of the linear regressions using the centered or uncentered regressions (it doesn’t matter which one). Perform a descriptive analysis on these residuals. This could include graphically visualizing the distribution and/or computing summary statistics on the residuals.

```{r}
ride$residuals <- resid(ride_lm)
```

Descriptive analysis of residuals (raw)

```{r}
gf_density(~ residuals, data = ride) %>%
  gf_labs(x = "Residuals")
```

```{r}
ggplot(ride, aes(sample = residuals)) + 
  stat_qq(size = 5) + 
  stat_qq_line(size = 2)
```

```{r}
df_stats(~residuals, data = ride, mean)
```

3.Evaluate the residuals for the assumption of normality of the residuals. How may the results be impacted by any deviation of normality?

4. Evaluate the residuals for the assumption of homogeneity of variance. How may the results be impacted by any deviation of homogeneity of variance?

```{r}
norm_residuals <- augment(ride_lm)
gf_density(~ .std.resid, data = norm_residuals) %>%
  gf_labs(x = "Standardized Residuals")
```

```{r}
gf_point(.std.resid ~ .fitted, data = norm_residuals, size = 4, alpha = .15) %>%
  gf_hline(yintercept = ~ 2, color = 'red', size = 1) %>%
  gf_hline(yintercept = ~ -2, color = 'red', size = 1) %>%
  gf_smooth(method = 'lm', size = 1.2) %>%
  gf_labs(x = 'Fitted Values',
          y = 'Standardized Residuals')
```

```{r}
gf_point(.resid ~ .fitted, data = norm_residuals, size = 4, alpha = .15) %>%
  gf_smooth(method = 'loess', size = 2) %>%
  gf_labs(x = 'Fitted Values',
          y = 'Residuals')
```

5. Are there any noticeable trends in the residuals? What implications could this have for the analysis? If a trend in the residuals exists, what may be a cause for this trend?

6. Explore the model to identify if there are any points that have high leverage or could be identified as extreme values. It may be worth exploring studentized residuals, cook’s distance, and/or leverage values.

Cook's distance

```{r}
norm_residuals %>%
  mutate(obs_num = 1:n()) %>%
  gf_col(.cooksd ~ obs_num, fill = 'black', color = 'black') %>%
  gf_labs(x = "Observation Number",
          y = "Cook's Distance")
```

Studentized residuals

```{r}
ride$student_residuals <- rstudent(ride_lm)
head(ride)
```

```{r}
ride %>%
  mutate(obs_num = 1:n()) %>%
  gf_point(student_residuals ~ obs_num, size = 5, alpha = .15) %>%
  gf_hline(yintercept = ~ 3, color = 'blue', size = 2) %>%
  gf_labs(x = "Observation Number",
          y = "Studentized Residuals")
```

```{r}
norm_residuals %>%
  mutate(obs_num = 1:n()) %>%
  gf_col(.hat ~ obs_num, fill = 'black', color = 'black') %>%
  gf_labs(x = "Observation Number",
          y = "Hat Values (leverage)")
```

```{r}
plot(ride_lm, which = 1:5)
```




